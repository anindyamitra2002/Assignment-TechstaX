{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fireducks seaborn torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fireducks.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7249346</th>\n",
       "      <td>A-7298709</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-04 09:03:00</td>\n",
       "      <td>2019-12-04 10:16:27</td>\n",
       "      <td>37.783193</td>\n",
       "      <td>-121.221919</td>\n",
       "      <td>37.783193</td>\n",
       "      <td>-121.221919</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016747</th>\n",
       "      <td>A-4046907</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-05-01 08:14:00</td>\n",
       "      <td>2022-05-01 08:34:00</td>\n",
       "      <td>40.708090</td>\n",
       "      <td>-73.844615</td>\n",
       "      <td>40.70266006671568</td>\n",
       "      <td>-73.86163522067143</td>\n",
       "      <td>0.967</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179911</th>\n",
       "      <td>A-1189687</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-18 08:09:02</td>\n",
       "      <td>2021-01-18 09:26:26</td>\n",
       "      <td>35.209850</td>\n",
       "      <td>-80.757179</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912761</th>\n",
       "      <td>A-6962046</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-25 13:35:30</td>\n",
       "      <td>2020-10-25 16:24:09</td>\n",
       "      <td>40.837638</td>\n",
       "      <td>-73.930251</td>\n",
       "      <td>40.844731</td>\n",
       "      <td>-73.92514399999997</td>\n",
       "      <td>0.558</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682983</th>\n",
       "      <td>A-692671</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-01 17:30:10</td>\n",
       "      <td>2022-03-01 17:58:15</td>\n",
       "      <td>37.085140</td>\n",
       "      <td>-76.455078</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749500</th>\n",
       "      <td>A-1759357</td>\n",
       "      <td>Source3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-16 15:06:50</td>\n",
       "      <td>2019-10-16 16:26:37</td>\n",
       "      <td>34.036102</td>\n",
       "      <td>-118.269379</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5579467</th>\n",
       "      <td>A-5621622</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-11-10 06:28:00</td>\n",
       "      <td>2021-11-10 08:52:55</td>\n",
       "      <td>30.428298</td>\n",
       "      <td>-97.670872</td>\n",
       "      <td>30.3818</td>\n",
       "      <td>-97.674094</td>\n",
       "      <td>3.218</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911654</th>\n",
       "      <td>A-4948872</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-03-03 16:31:00.000000000</td>\n",
       "      <td>2022-03-03 19:28:43.000000000</td>\n",
       "      <td>38.832491</td>\n",
       "      <td>-77.314387</td>\n",
       "      <td>38.826375</td>\n",
       "      <td>-77.31673</td>\n",
       "      <td>0.441</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111094</th>\n",
       "      <td>A-1120868</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-12 09:42:41</td>\n",
       "      <td>2021-03-12 10:44:08</td>\n",
       "      <td>43.177132</td>\n",
       "      <td>-83.814087</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7552348</th>\n",
       "      <td>A-7601716</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-06 07:26:28</td>\n",
       "      <td>2018-03-06 13:26:28</td>\n",
       "      <td>41.757610</td>\n",
       "      <td>-72.700550</td>\n",
       "      <td>41.76787</td>\n",
       "      <td>-72.68365</td>\n",
       "      <td>1.123</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 46 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/teamspace/studios/this_studio/Assignment-TechstaX/data/US_Accidents_March23.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7728394, 46)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "\n",
      "ID                             0\n",
      "Source                         0\n",
      "Severity                       0\n",
      "Start_Time                     0\n",
      "End_Time                       0\n",
      "Start_Lat                      0\n",
      "Start_Lng                      0\n",
      "End_Lat                  3402762\n",
      "End_Lng                  3402762\n",
      "Distance(mi)                   0\n",
      "Description                    5\n",
      "Street                     10869\n",
      "City                         253\n",
      "County                         0\n",
      "State                          0\n",
      "Zipcode                     1915\n",
      "Country                        0\n",
      "Timezone                    7808\n",
      "Airport_Code               22635\n",
      "Weather_Timestamp         120228\n",
      "Temperature(F)            163853\n",
      "Wind_Chill(F)            1999019\n",
      "Humidity(%)               174144\n",
      "Pressure(in)              140679\n",
      "Visibility(mi)            177098\n",
      "Wind_Direction            175206\n",
      "Wind_Speed(mph)           571233\n",
      "Precipitation(in)        2203586\n",
      "Weather_Condition         173459\n",
      "Amenity                        0\n",
      "Bump                           0\n",
      "Crossing                       0\n",
      "Give_Way                       0\n",
      "Junction                       0\n",
      "No_Exit                        0\n",
      "Railway                        0\n",
      "Roundabout                     0\n",
      "Station                        0\n",
      "Stop                           0\n",
      "Traffic_Calming                0\n",
      "Traffic_Signal                 0\n",
      "Turning_Loop                   0\n",
      "Sunrise_Sunset             23246\n",
      "Civil_Twilight             23246\n",
      "Nautical_Twilight          23246\n",
      "Astronomical_Twilight      23246\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null values in each column\n",
    "null_values = data.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n\")\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows with no null values: 3554549\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows with no null values\n",
    "rows_with_no_nulls = data.dropna().shape[0]\n",
    "print(\"\\nNumber of rows with no null values:\", rows_with_no_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities: 1\n",
      "Unique states: 49\n"
     ]
    }
   ],
   "source": [
    "unique_city = len(data[['Country']].value_counts())\n",
    "unique_state = len(data[['State']].value_counts())\n",
    "\n",
    "print(\"Unique cities:\", unique_city)\n",
    "print(\"Unique states:\", unique_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values and frequencies for column 'ID' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/ID_frequencies.csv\n",
      "Unique values and frequencies for column 'Source' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Source_frequencies.csv\n",
      "Unique values and frequencies for column 'Severity' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Severity_frequencies.csv\n",
      "Unique values and frequencies for column 'Start_Time' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Start_Time_frequencies.csv\n",
      "Unique values and frequencies for column 'End_Time' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/End_Time_frequencies.csv\n",
      "Unique values and frequencies for column 'Start_Lat' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Start_Lat_frequencies.csv\n",
      "Unique values and frequencies for column 'Start_Lng' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Start_Lng_frequencies.csv\n",
      "Unique values and frequencies for column 'End_Lat' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/End_Lat_frequencies.csv\n",
      "Unique values and frequencies for column 'End_Lng' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/End_Lng_frequencies.csv\n",
      "Unique values and frequencies for column 'Distance(mi)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Distance(mi)_frequencies.csv\n",
      "Unique values and frequencies for column 'Description' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Description_frequencies.csv\n",
      "Unique values and frequencies for column 'Street' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Street_frequencies.csv\n",
      "Unique values and frequencies for column 'City' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/City_frequencies.csv\n",
      "Unique values and frequencies for column 'County' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/County_frequencies.csv\n",
      "Unique values and frequencies for column 'State' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/State_frequencies.csv\n",
      "Unique values and frequencies for column 'Zipcode' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Zipcode_frequencies.csv\n",
      "Unique values and frequencies for column 'Country' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Country_frequencies.csv\n",
      "Unique values and frequencies for column 'Timezone' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Timezone_frequencies.csv\n",
      "Unique values and frequencies for column 'Airport_Code' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Airport_Code_frequencies.csv\n",
      "Unique values and frequencies for column 'Weather_Timestamp' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Weather_Timestamp_frequencies.csv\n",
      "Unique values and frequencies for column 'Temperature(F)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Temperature(F)_frequencies.csv\n",
      "Unique values and frequencies for column 'Wind_Chill(F)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Wind_Chill(F)_frequencies.csv\n",
      "Unique values and frequencies for column 'Humidity(%)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Humidity(%)_frequencies.csv\n",
      "Unique values and frequencies for column 'Pressure(in)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Pressure(in)_frequencies.csv\n",
      "Unique values and frequencies for column 'Visibility(mi)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Visibility(mi)_frequencies.csv\n",
      "Unique values and frequencies for column 'Wind_Direction' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Wind_Direction_frequencies.csv\n",
      "Unique values and frequencies for column 'Wind_Speed(mph)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Wind_Speed(mph)_frequencies.csv\n",
      "Unique values and frequencies for column 'Precipitation(in)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Precipitation(in)_frequencies.csv\n",
      "Unique values and frequencies for column 'Weather_Condition' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Weather_Condition_frequencies.csv\n",
      "Unique values and frequencies for column 'Amenity' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Amenity_frequencies.csv\n",
      "Unique values and frequencies for column 'Bump' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Bump_frequencies.csv\n",
      "Unique values and frequencies for column 'Crossing' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Crossing_frequencies.csv\n",
      "Unique values and frequencies for column 'Give_Way' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Give_Way_frequencies.csv\n",
      "Unique values and frequencies for column 'Junction' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Junction_frequencies.csv\n",
      "Unique values and frequencies for column 'No_Exit' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/No_Exit_frequencies.csv\n",
      "Unique values and frequencies for column 'Railway' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Railway_frequencies.csv\n",
      "Unique values and frequencies for column 'Roundabout' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Roundabout_frequencies.csv\n",
      "Unique values and frequencies for column 'Station' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Station_frequencies.csv\n",
      "Unique values and frequencies for column 'Stop' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Stop_frequencies.csv\n",
      "Unique values and frequencies for column 'Traffic_Calming' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Traffic_Calming_frequencies.csv\n",
      "Unique values and frequencies for column 'Traffic_Signal' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Traffic_Signal_frequencies.csv\n",
      "Unique values and frequencies for column 'Turning_Loop' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Turning_Loop_frequencies.csv\n",
      "Unique values and frequencies for column 'Sunrise_Sunset' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Sunrise_Sunset_frequencies.csv\n",
      "Unique values and frequencies for column 'Civil_Twilight' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Civil_Twilight_frequencies.csv\n",
      "Unique values and frequencies for column 'Nautical_Twilight' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Nautical_Twilight_frequencies.csv\n",
      "Unique values and frequencies for column 'Astronomical_Twilight' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Astronomical_Twilight_frequencies.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = '/teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through each column and calculate unique values and their frequencies\n",
    "for column in data.columns:\n",
    "    unique_counts = data[column].value_counts(dropna=False)  # Include NaN values\n",
    "    output_df = unique_counts.reset_index()  # Convert to DataFrame\n",
    "    output_df.columns = ['Unique_Value', 'Frequency']  # Rename columns\n",
    "    \n",
    "    # Save the unique value frequencies to a CSV file\n",
    "    output_file = os.path.join(output_dir, f\"{column}_frequencies.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(f\"Unique values and frequencies for column '{column}' saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:The following columns were not found in the dataset: {'Number', 'Side'}\n",
      "INFO:__main__:Successfully dropped 14 columns\n",
      "INFO:__main__:DataFrame shape changed from (7728394, 46) to (7728394, 32)\n",
      "INFO:fireducks.fallback:fallback_attr: name=Index.tolist reason=Index.__getattr__ for tolist is called \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Severity', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng', 'Distance(mi)', 'Description', 'City', 'County', 'State', 'Timezone', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Sunrise_Sunset']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "def drop_redundant_columns(df):\n",
    "    \"\"\"\n",
    "    Drops redundant columns from the accidents dataset.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame with accident data\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with redundant columns removed\n",
    "    \"\"\"\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # List of columns to drop\n",
    "    redundant_columns = [\n",
    "        'Source',\n",
    "        'End_Lat',\n",
    "        'End_Lng',\n",
    "        'Number',\n",
    "        'Street',\n",
    "        'Country',\n",
    "        'Airport_Code',\n",
    "        'Civil_Twilight',\n",
    "        'Nautical_Twilight',\n",
    "        'Astronomical_Twilight',\n",
    "        'Weather_Timestamp',\n",
    "        'ID',\n",
    "        'Turning_Loop',\n",
    "        'Wind_Chill(F)',\n",
    "        'Side',\n",
    "        'Zipcode'\n",
    "    ]\n",
    "    \n",
    "    # Store original shape\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    try:\n",
    "        # Check which columns actually exist in the dataframe\n",
    "        columns_to_drop = [col for col in redundant_columns if col in df.columns]\n",
    "        \n",
    "        # Log any columns that were in our list but not in the dataframe\n",
    "        missing_columns = set(redundant_columns) - set(df.columns)\n",
    "        if missing_columns:\n",
    "            logger.warning(f\"The following columns were not found in the dataset: {missing_columns}\")\n",
    "        \n",
    "        # Drop the columns\n",
    "        df_cleaned = df.drop(columns=columns_to_drop)\n",
    "        \n",
    "        # Log the results\n",
    "        columns_dropped = len(columns_to_drop)\n",
    "        logger.info(f\"Successfully dropped {columns_dropped} columns\")\n",
    "        logger.info(f\"DataFrame shape changed from {original_shape} to {df_cleaned.shape}\")\n",
    "        \n",
    "        return df_cleaned\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while dropping columns: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "# Example usage:\n",
    "data = drop_redundant_columns(data)\n",
    "\n",
    "# To verify the remaining columns:\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.map reason=input 'arg' is neither a dict nor a type to be casted \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 11 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather_Group\n",
      "Clear                  3405216\n",
      "Cloudy                 3163728\n",
      "Rain                    510564\n",
      "Poor Visibility         201398\n",
      "Unknown                 178798\n",
      "Snow                    160008\n",
      "Thunderstorm             88452\n",
      "Mixed Precipitation      13247\n",
      "Freezing Conditions       6049\n",
      "Dust/Sand                  747\n",
      "Severe Conditions          187\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_weather_conditions(weather_series):\n",
    "    \"\"\"\n",
    "    Groups weather conditions into broader categories.\n",
    "    \n",
    "    Args:\n",
    "        weather_series: pandas Series containing weather conditions\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with grouped weather conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create mapping dictionary for weather conditions\n",
    "    weather_mapping = {\n",
    "        # Clear conditions\n",
    "        'Fair': 'Clear',\n",
    "        'Clear': 'Clear',\n",
    "        'Fair / Windy': 'Clear',\n",
    "        \n",
    "        # Cloudy conditions\n",
    "        'Mostly Cloudy': 'Cloudy',\n",
    "        'Cloudy': 'Cloudy',\n",
    "        'Partly Cloudy': 'Cloudy',\n",
    "        'Overcast': 'Cloudy',\n",
    "        'Scattered Clouds': 'Cloudy',\n",
    "        'Cloudy / Windy': 'Cloudy',\n",
    "        'Mostly Cloudy / Windy': 'Cloudy',\n",
    "        'Partly Cloudy / Windy': 'Cloudy',\n",
    "        \n",
    "        # Rain conditions\n",
    "        'Light Rain': 'Rain',\n",
    "        'Rain': 'Rain',\n",
    "        'Heavy Rain': 'Rain',\n",
    "        'Light Drizzle': 'Rain',\n",
    "        'Light Rain / Windy': 'Rain',\n",
    "        'Rain / Windy': 'Rain',\n",
    "        'Heavy Rain / Windy': 'Rain',\n",
    "        'Drizzle': 'Rain',\n",
    "        'Light Rain Shower': 'Rain',\n",
    "        'Rain Shower': 'Rain',\n",
    "        'Rain Showers': 'Rain',\n",
    "        'Heavy Drizzle': 'Rain',\n",
    "        'Light Rain Showers': 'Rain',\n",
    "        'Heavy Rain Showers': 'Rain',\n",
    "        'Light Drizzle / Windy': 'Rain',\n",
    "        'Drizzle / Windy': 'Rain',\n",
    "        'Rain Shower / Windy': 'Rain',\n",
    "        'Heavy Rain Shower / Windy': 'Rain',\n",
    "        'Drizzle and Fog': 'Rain',\n",
    "        \n",
    "        # Snow conditions\n",
    "        'Light Snow': 'Snow',\n",
    "        'Snow': 'Snow',\n",
    "        'Heavy Snow': 'Snow',\n",
    "        'Light Snow / Windy': 'Snow',\n",
    "        'Snow / Windy': 'Snow',\n",
    "        'Heavy Snow / Windy': 'Snow',\n",
    "        'Blowing Snow': 'Snow',\n",
    "        'Blowing Snow / Windy': 'Snow',\n",
    "        'Light Snow Shower': 'Snow',\n",
    "        'Snow Showers': 'Snow',\n",
    "        'Light Snow Showers': 'Snow',\n",
    "        'Light Snow Shower / Windy': 'Snow',\n",
    "        'Snow Grains': 'Snow',\n",
    "        'Light Snow Grains': 'Snow',\n",
    "        'Drifting Snow': 'Snow',\n",
    "        'Drifting Snow / Windy': 'Snow',\n",
    "        'Low Drifting Snow': 'Snow',\n",
    "        'Heavy Blowing Snow': 'Snow',\n",
    "        'Light Blowing Snow': 'Snow',\n",
    "        'Blowing Snow Nearby': 'Snow',\n",
    "        \n",
    "        # Thunderstorm conditions\n",
    "        'Thunder': 'Thunderstorm',\n",
    "        'T-Storm': 'Thunderstorm',\n",
    "        'Heavy T-Storm': 'Thunderstorm',\n",
    "        'Thunder in the Vicinity': 'Thunderstorm',\n",
    "        'Light Rain with Thunder': 'Thunderstorm',\n",
    "        'Light Thunderstorms and Rain': 'Thunderstorm',\n",
    "        'Thunderstorm': 'Thunderstorm',\n",
    "        'Heavy Thunderstorms and Rain': 'Thunderstorm',\n",
    "        'Thunderstorms and Rain': 'Thunderstorm',\n",
    "        'Heavy T-Storm / Windy': 'Thunderstorm',\n",
    "        'T-Storm / Windy': 'Thunderstorm',\n",
    "        'Thunder / Windy': 'Thunderstorm',\n",
    "        'Thunder and Hail': 'Thunderstorm',\n",
    "        'Thunder and Hail / Windy': 'Thunderstorm',\n",
    "        'Light Thunderstorm': 'Thunderstorm',\n",
    "        \n",
    "        # Freezing conditions\n",
    "        'Light Freezing Rain': 'Freezing Conditions',\n",
    "        'Light Freezing Drizzle': 'Freezing Conditions',\n",
    "        'Freezing Rain': 'Freezing Conditions',\n",
    "        'Freezing Drizzle': 'Freezing Conditions',\n",
    "        'Heavy Freezing Rain': 'Freezing Conditions',\n",
    "        'Light Freezing Rain / Windy': 'Freezing Conditions',\n",
    "        'Freezing Rain / Windy': 'Freezing Conditions',\n",
    "        'Heavy Freezing Rain / Windy': 'Freezing Conditions',\n",
    "        'Heavy Freezing Drizzle': 'Freezing Conditions',\n",
    "        'Light Freezing Fog': 'Freezing Conditions',\n",
    "        \n",
    "        # Mixed precipitation\n",
    "        'Wintry Mix': 'Mixed Precipitation',\n",
    "        'Snow and Sleet': 'Mixed Precipitation',\n",
    "        'Light Snow and Sleet': 'Mixed Precipitation',\n",
    "        'Wintry Mix / Windy': 'Mixed Precipitation',\n",
    "        'Snow and Sleet / Windy': 'Mixed Precipitation',\n",
    "        'Light Snow and Sleet / Windy': 'Mixed Precipitation',\n",
    "        'Thunder / Wintry Mix': 'Mixed Precipitation',\n",
    "        'Thunder / Wintry Mix / Windy': 'Mixed Precipitation',\n",
    "        'Rain and Sleet': 'Mixed Precipitation',\n",
    "        'Sleet': 'Mixed Precipitation',\n",
    "        'Light Sleet': 'Mixed Precipitation',\n",
    "        'Heavy Sleet': 'Mixed Precipitation',\n",
    "        'Sleet / Windy': 'Mixed Precipitation',\n",
    "        'Light Sleet / Windy': 'Mixed Precipitation',\n",
    "        'Heavy Sleet / Windy': 'Mixed Precipitation',\n",
    "        \n",
    "        # Poor visibility conditions\n",
    "        'Fog': 'Poor Visibility',\n",
    "        'Haze': 'Poor Visibility',\n",
    "        'Smoke': 'Poor Visibility',\n",
    "        'Fog / Windy': 'Poor Visibility',\n",
    "        'Haze / Windy': 'Poor Visibility',\n",
    "        'Smoke / Windy': 'Poor Visibility',\n",
    "        'Patches of Fog': 'Poor Visibility',\n",
    "        'Mist': 'Poor Visibility',\n",
    "        'Shallow Fog': 'Poor Visibility',\n",
    "        'Patches of Fog / Windy': 'Poor Visibility',\n",
    "        'Mist / Windy': 'Poor Visibility',\n",
    "        'Shallow Fog / Windy': 'Poor Visibility',\n",
    "        'Light Haze': 'Poor Visibility',\n",
    "        'Light Fog': 'Poor Visibility',\n",
    "        'Partial Fog': 'Poor Visibility',\n",
    "        'Partial Fog / Windy': 'Poor Visibility',\n",
    "        'Heavy Smoke': 'Poor Visibility',\n",
    "        \n",
    "        # Severe conditions\n",
    "        'Tornado': 'Severe Conditions',\n",
    "        'Funnel Cloud': 'Severe Conditions',\n",
    "        'Small Hail': 'Severe Conditions',\n",
    "        'Hail': 'Severe Conditions',\n",
    "        'Light Hail': 'Severe Conditions',\n",
    "        'Volcanic Ash': 'Severe Conditions',\n",
    "        'Heavy Thunderstorms with Small Hail': 'Severe Conditions',\n",
    "        \n",
    "        # Dust/Sand conditions\n",
    "        'Blowing Dust': 'Dust/Sand',\n",
    "        'Widespread Dust': 'Dust/Sand',\n",
    "        'Sand / Dust Whirlwinds': 'Dust/Sand',\n",
    "        'Blowing Dust / Windy': 'Dust/Sand',\n",
    "        'Widespread Dust / Windy': 'Dust/Sand',\n",
    "        'Sand': 'Dust/Sand',\n",
    "        'Sand / Dust Whirls Nearby': 'Dust/Sand',\n",
    "        'Sand / Dust Whirlwinds / Windy': 'Dust/Sand',\n",
    "        'Duststorm': 'Dust/Sand',\n",
    "        'Blowing Sand': 'Dust/Sand',\n",
    "        'Dust Whirls': 'Dust/Sand',\n",
    "        'Sand / Windy': 'Dust/Sand'\n",
    "    }\n",
    "    \n",
    "    # Replace empty strings and N/A with 'Unknown'\n",
    "    weather_series = weather_series.fillna('Unknown')\n",
    "    weather_series = weather_series.replace('', 'Unknown')\n",
    "    weather_series = weather_series.replace('N/A Precipitation', 'Unknown')\n",
    "    \n",
    "    # Map the weather conditions to their groups\n",
    "    return weather_series.map(lambda x: weather_mapping.get(x, 'Unknown'))\n",
    "\n",
    "data['Weather_Group'] = group_weather_conditions(data['Weather_Condition'])\n",
    "data = data.drop(columns=['Weather_Condition'])\n",
    "# To see the distribution of the new groups\n",
    "print(data['Weather_Group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.map reason=input 'arg' is neither a dict nor a type to be casted \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 11 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind_Direction_Group\n",
      "South        1331314\n",
      "Calm         1330181\n",
      "West         1281251\n",
      "North        1049274\n",
      "East          909244\n",
      "Northwest     369352\n",
      "Variable      364562\n",
      "Southwest     364470\n",
      "Southeast     294901\n",
      "Northeast     258639\n",
      "Unknown       175206\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_wind_directions(wind_series):\n",
    "    \"\"\"\n",
    "    Groups wind directions into 8 main cardinal directions.\n",
    "    \n",
    "    Args:\n",
    "        wind_series: pandas Series containing wind directions\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with grouped wind directions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create mapping dictionary for wind directions\n",
    "    wind_mapping = {\n",
    "        # North (337.5° - 22.5°)\n",
    "        'N': 'North',\n",
    "        'North': 'North',\n",
    "        'NNE': 'North',\n",
    "        'NNW': 'North',\n",
    "        \n",
    "        # East (67.5° - 112.5°)\n",
    "        'E': 'East',\n",
    "        'East': 'East',\n",
    "        'ENE': 'East',\n",
    "        'ESE': 'East',\n",
    "        \n",
    "        # South (157.5° - 202.5°)\n",
    "        'S': 'South',\n",
    "        'South': 'South',\n",
    "        'SSE': 'South',\n",
    "        'SSW': 'South',\n",
    "        \n",
    "        # West (247.5° - 292.5°)\n",
    "        'W': 'West',\n",
    "        'West': 'West',\n",
    "        'WNW': 'West',\n",
    "        'WSW': 'West',\n",
    "        \n",
    "        # Northeast (22.5° - 67.5°)\n",
    "        'NE': 'Northeast',\n",
    "        \n",
    "        # Southeast (112.5° - 157.5°)\n",
    "        'SE': 'Southeast',\n",
    "        \n",
    "        # Southwest (202.5° - 247.5°)\n",
    "        'SW': 'Southwest',\n",
    "        \n",
    "        # Northwest (292.5° - 337.5°)\n",
    "        'NW': 'Northwest',\n",
    "        \n",
    "        # Calm/Variable conditions\n",
    "        'CALM': 'Calm',\n",
    "        'Calm': 'Calm',\n",
    "        'VAR': 'Variable',\n",
    "        'Variable': 'Variable'\n",
    "    }\n",
    "    \n",
    "    # Replace empty strings and missing values with 'Unknown'\n",
    "    wind_series = wind_series.fillna('Unknown')\n",
    "    wind_series = wind_series.replace('', 'Unknown')\n",
    "    \n",
    "    # Map the wind directions to their groups\n",
    "    return wind_series.map(lambda x: wind_mapping.get(x, 'Unknown'))\n",
    "\n",
    "\n",
    "data['Wind_Direction_Group'] = group_wind_directions(data['Wind_Direction'])\n",
    "data.drop(columns=['Wind_Direction'], inplace=True)\n",
    "# To see the distribution of the new groups\n",
    "print(data['Wind_Direction_Group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series._typ reason=Series.__getattr__ for _typ is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series.__iter__ reason=Installed fallback wrapper for Series.__iter__ is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series._values reason=Series.__getattr__ for _values is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series._constructor reason=Series.__getattr__ for _constructor is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=DataFrame.__setitem__ reason=value is not FireDucksPandasCompat \n",
      "INFO:fireducks.fallback:fallback_attr: name=RangeIndex._can_hold_identifiers_and_holds_name reason=RangeIndex.__getattr__ for _can_hold_identifiers_and_holds_name is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=RangeIndex.equals reason=RangeIndex.__getattr__ for equals is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series._typ reason=Series.__getattr__ for _typ is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series.__iter__ reason=Installed fallback wrapper for Series.__iter__ is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series._values reason=Series.__getattr__ for _values is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series._constructor reason=Series.__getattr__ for _constructor is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=DataFrame.__setitem__ reason=value is not FireDucksPandasCompat \n",
      "INFO:fireducks.fallback:fallback_attr: name=RangeIndex._can_hold_identifiers_and_holds_name reason=RangeIndex.__getattr__ for _can_hold_identifiers_and_holds_name is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=RangeIndex.equals reason=RangeIndex.__getattr__ for equals is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series.apply reason=None \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 5 \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 8 \n",
      "INFO:fireducks.fallback:fallback_attr: name=DataFrame.__repr__ reason=with full data of size: 5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of day distribution:\n",
      "Time_Of_Day\n",
      "Morning      2859847\n",
      "Afternoon    1683839\n",
      "Noon         1200292\n",
      "Evening      1143841\n",
      "Night         840575\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Duration statistics (in minutes):\n",
      "count    7.728394e+06\n",
      "mean     4.444210e+02\n",
      "std      1.351229e+04\n",
      "min      1.220000e+00\n",
      "25%      3.150000e+01\n",
      "50%      7.483000e+01\n",
      "75%      1.251500e+02\n",
      "max      2.812939e+06\n",
      "Name: Duration_Minutes, dtype: float64\n",
      "\n",
      "Sample of processed data:\n",
      "           Start_Time            End_Time Time_Of_Day  Duration_Minutes\n",
      "0 2016-02-08 05:46:00 2016-02-08 11:00:00     Morning             314.0\n",
      "1 2016-02-08 06:07:59 2016-02-08 06:37:59     Morning              30.0\n",
      "2 2016-02-08 06:49:27 2016-02-08 07:19:27     Morning              30.0\n",
      "3 2016-02-08 07:23:34 2016-02-08 07:53:34     Morning              30.0\n",
      "4 2016-02-08 07:39:07 2016-02-08 08:09:07     Morning              30.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def categorize_time_of_day(hour):\n",
    "    \"\"\"\n",
    "    Categorizes the hour into time of day\n",
    "    \n",
    "    Args:\n",
    "        hour: int (0-23)\n",
    "    Returns:\n",
    "        str: time of day category\n",
    "    \"\"\"\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 15:\n",
    "        return 'Noon'\n",
    "    elif 15 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "def process_time_features(df):\n",
    "    \"\"\"\n",
    "    Process time-related features:\n",
    "    1. Extract time of day from Start_Time\n",
    "    2. Calculate accident duration in minutes\n",
    "    3. Drop Sunrise_Sunset column\n",
    "    4. Extract year, month, day from Start_Time\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with Start_Time and End_Time columns\n",
    "    Returns:\n",
    "        pandas DataFrame with new time features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert Start_Time and End_Time to datetime using a more flexible parser\n",
    "        df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='mixed')\n",
    "        df['End_Time'] = pd.to_datetime(df['End_Time'], format='mixed')\n",
    "        \n",
    "        # Extract year, month, and day from Start_Time\n",
    "        df['Year'] = df['Start_Time'].dt.year\n",
    "        df['Month'] = df['Start_Time'].dt.month\n",
    "        df['Day'] = df['Start_Time'].dt.day\n",
    "        \n",
    "        # Extract hour from Start_Time\n",
    "        df['Hour'] = df['Start_Time'].dt.hour\n",
    "        \n",
    "        # Add Time_Of_Day column\n",
    "        df['Time_Of_Day'] = df['Hour'].apply(categorize_time_of_day)\n",
    "        \n",
    "        # Calculate duration in minutes\n",
    "        df['Duration_Minutes'] = ((df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60).round(2)\n",
    "        \n",
    "        # Drop intermediate and redundant columns\n",
    "        columns_to_drop = ['Hour', 'Sunrise_Sunset']\n",
    "        existing_columns = [col for col in columns_to_drop if col in df.columns]\n",
    "        df = df.drop(columns=existing_columns)\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"Time of day distribution:\\n{df['Time_Of_Day'].value_counts()}\\n\")\n",
    "        print(f\"Duration statistics (in minutes):\\n{df['Duration_Minutes'].describe()}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing time features: {str(e)}\")\n",
    "        # Print some example problematic rows if there's an error\n",
    "        if 'Start_Time' in df.columns:\n",
    "            print(\"\\nExample timestamp formats in the data:\")\n",
    "            print(df['Start_Time'].head(5))\n",
    "        raise\n",
    "\n",
    "# Process the time features\n",
    "data = process_time_features(data)\n",
    "\n",
    "# To verify the results\n",
    "print(\"\\nSample of processed data:\")\n",
    "print(data[['Start_Time', 'End_Time', 'Year', 'Month', 'Day', 'Time_Of_Day', 'Duration_Minutes']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Start_Time', 'End_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=DataFrame.select_dtypes reason=DataFrame.__getattr__ for select_dtypes is called \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 8 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description             3761579\n",
      "City                      13679\n",
      "County                     1871\n",
      "State                        49\n",
      "Timezone                      5\n",
      "Weather_Group                11\n",
      "Wind_Direction_Group         11\n",
      "Time_Of_Day                   5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique values for each object (non-numeric) column\n",
    "unique_counts = data.select_dtypes(include=['object']).nunique()\n",
    "\n",
    "# Print the unique counts for each object column\n",
    "print(unique_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Right lane blocked due to accident on I-70 Eas...\n",
      "1    Accident on Brice Rd at Tussing Rd. Expect del...\n",
      "2    Accident on OH-32 State Route 32 Westbound at ...\n",
      "3    Accident on I-75 Southbound at Exits 52 52B US...\n",
      "4    Accident on McEwen Rd at OH-725 Miamisburg Cen...\n",
      "5    Accident on I-270 Outerbelt Northbound near Ex...\n",
      "6    Accident on Oakridge Dr at Woodward Ave. Expec...\n",
      "7    Accident on I-75 Southbound at Exit 54B Grand ...\n",
      "8    Accident on Notre Dame Ave at Warner Ave. Expe...\n",
      "9    Right hand shoulder blocked due to accident on...\n",
      "Name: Description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['Description'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.apply reason=None \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12.248763067721443, 119, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Description_word_length'] = data['Description'].apply(lambda x: len(str(x).split()))\n",
    "avg_word_length = data['Description_word_length'].mean()\n",
    "max_word_length = data['Description_word_length'].max()\n",
    "min_word_length = data['Description_word_length'].min()\n",
    "\n",
    "avg_word_length, max_word_length, min_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 32 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "\n",
      "Severity                         0\n",
      "Start_Lat                        0\n",
      "Start_Lng                        0\n",
      "Distance(mi)                     0\n",
      "Description                      5\n",
      "City                           253\n",
      "County                           0\n",
      "State                            0\n",
      "Timezone                      7808\n",
      "Temperature(F)              163853\n",
      "Humidity(%)                 174144\n",
      "Pressure(in)                140679\n",
      "Visibility(mi)              177098\n",
      "Wind_Speed(mph)             571233\n",
      "Precipitation(in)          2203586\n",
      "Amenity                          0\n",
      "Bump                             0\n",
      "Crossing                         0\n",
      "Give_Way                         0\n",
      "Junction                         0\n",
      "No_Exit                          0\n",
      "Railway                          0\n",
      "Roundabout                       0\n",
      "Station                          0\n",
      "Stop                             0\n",
      "Traffic_Calming                  0\n",
      "Traffic_Signal                   0\n",
      "Weather_Group                    0\n",
      "Wind_Direction_Group             0\n",
      "Time_Of_Day                      0\n",
      "Duration_Minutes                 0\n",
      "Description_word_length          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null values in each column\n",
    "null_values = data.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n\")\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/teamspace/studios/this_studio/Assignment-TechstaX/data/cleaned_accidents_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
