{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fireducks seaborn torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fireducks.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1088710</th>\n",
       "      <td>A-1098482</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-03-31 22:44:10</td>\n",
       "      <td>2021-04-01 00:49:03</td>\n",
       "      <td>40.929298</td>\n",
       "      <td>-73.766525</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548268</th>\n",
       "      <td>A-3558151</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-27 08:43:01</td>\n",
       "      <td>2017-01-27 14:43:01</td>\n",
       "      <td>26.542490</td>\n",
       "      <td>-80.071970</td>\n",
       "      <td>26.550655</td>\n",
       "      <td>-80.07002</td>\n",
       "      <td>0.577</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116022</th>\n",
       "      <td>A-116029</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-20 16:24:26</td>\n",
       "      <td>2016-06-20 17:09:26</td>\n",
       "      <td>32.831978</td>\n",
       "      <td>-116.905060</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596066</th>\n",
       "      <td>A-602664</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-06-06 08:58:14</td>\n",
       "      <td>2022-06-06 09:27:51</td>\n",
       "      <td>30.492378</td>\n",
       "      <td>-91.163429</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838552</th>\n",
       "      <td>A-848266</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-10-22 12:54:01</td>\n",
       "      <td>2021-10-22 13:23:51</td>\n",
       "      <td>33.654629</td>\n",
       "      <td>-111.908119</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7331807</th>\n",
       "      <td>A-7381173</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-13 06:46:00</td>\n",
       "      <td>2019-11-13 08:20:44</td>\n",
       "      <td>34.291152</td>\n",
       "      <td>-118.467761</td>\n",
       "      <td>34.291152000000004</td>\n",
       "      <td>-118.467761</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096849</th>\n",
       "      <td>A-1106622</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-25 14:11:11</td>\n",
       "      <td>2021-03-25 15:13:43</td>\n",
       "      <td>36.078991</td>\n",
       "      <td>-95.886398</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834734</th>\n",
       "      <td>A-1844597</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-11-26 18:05:44</td>\n",
       "      <td>2019-11-26 19:59:17</td>\n",
       "      <td>42.784470</td>\n",
       "      <td>-71.507797</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748089</th>\n",
       "      <td>A-5791247</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-14 16:49:14</td>\n",
       "      <td>2021-12-14 17:16:37</td>\n",
       "      <td>25.572599</td>\n",
       "      <td>-80.375550</td>\n",
       "      <td>25.566261</td>\n",
       "      <td>-80.381753</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4339553</th>\n",
       "      <td>A-4372368</td>\n",
       "      <td>Source1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-07-06 16:22:45</td>\n",
       "      <td>2022-07-06 17:41:43</td>\n",
       "      <td>27.966649</td>\n",
       "      <td>-82.786945</td>\n",
       "      <td>27.968148</td>\n",
       "      <td>-82.786952</td>\n",
       "      <td>0.104</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 46 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/teamspace/studios/this_studio/Assignment-TechstaX/data/US_Accidents_March23.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7728394, 46)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "\n",
      "ID                             0\n",
      "Source                         0\n",
      "Severity                       0\n",
      "Start_Time                     0\n",
      "End_Time                       0\n",
      "Start_Lat                      0\n",
      "Start_Lng                      0\n",
      "End_Lat                  3402762\n",
      "End_Lng                  3402762\n",
      "Distance(mi)                   0\n",
      "Description                    5\n",
      "Street                     10869\n",
      "City                         253\n",
      "County                         0\n",
      "State                          0\n",
      "Zipcode                     1915\n",
      "Country                        0\n",
      "Timezone                    7808\n",
      "Airport_Code               22635\n",
      "Weather_Timestamp         120228\n",
      "Temperature(F)            163853\n",
      "Wind_Chill(F)            1999019\n",
      "Humidity(%)               174144\n",
      "Pressure(in)              140679\n",
      "Visibility(mi)            177098\n",
      "Wind_Direction            175206\n",
      "Wind_Speed(mph)           571233\n",
      "Precipitation(in)        2203586\n",
      "Weather_Condition         173459\n",
      "Amenity                        0\n",
      "Bump                           0\n",
      "Crossing                       0\n",
      "Give_Way                       0\n",
      "Junction                       0\n",
      "No_Exit                        0\n",
      "Railway                        0\n",
      "Roundabout                     0\n",
      "Station                        0\n",
      "Stop                           0\n",
      "Traffic_Calming                0\n",
      "Traffic_Signal                 0\n",
      "Turning_Loop                   0\n",
      "Sunrise_Sunset             23246\n",
      "Civil_Twilight             23246\n",
      "Nautical_Twilight          23246\n",
      "Astronomical_Twilight      23246\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null values in each column\n",
    "null_values = data.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n\")\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows with no null values: 3554549\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows with no null values\n",
    "rows_with_no_nulls = data.dropna().shape[0]\n",
    "print(\"\\nNumber of rows with no null values:\", rows_with_no_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities: 1\n",
      "Unique states: 49\n"
     ]
    }
   ],
   "source": [
    "unique_city = len(data[['Country']].value_counts())\n",
    "unique_state = len(data[['State']].value_counts())\n",
    "\n",
    "print(\"Unique cities:\", unique_city)\n",
    "print(\"Unique states:\", unique_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values and frequencies for column 'ID' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/ID_frequencies.csv\n",
      "Unique values and frequencies for column 'Source' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Source_frequencies.csv\n",
      "Unique values and frequencies for column 'Severity' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Severity_frequencies.csv\n",
      "Unique values and frequencies for column 'Start_Time' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Start_Time_frequencies.csv\n",
      "Unique values and frequencies for column 'End_Time' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/End_Time_frequencies.csv\n",
      "Unique values and frequencies for column 'Start_Lat' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Start_Lat_frequencies.csv\n",
      "Unique values and frequencies for column 'Start_Lng' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Start_Lng_frequencies.csv\n",
      "Unique values and frequencies for column 'End_Lat' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/End_Lat_frequencies.csv\n",
      "Unique values and frequencies for column 'End_Lng' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/End_Lng_frequencies.csv\n",
      "Unique values and frequencies for column 'Distance(mi)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Distance(mi)_frequencies.csv\n",
      "Unique values and frequencies for column 'Description' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Description_frequencies.csv\n",
      "Unique values and frequencies for column 'Street' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Street_frequencies.csv\n",
      "Unique values and frequencies for column 'City' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/City_frequencies.csv\n",
      "Unique values and frequencies for column 'County' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/County_frequencies.csv\n",
      "Unique values and frequencies for column 'State' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/State_frequencies.csv\n",
      "Unique values and frequencies for column 'Zipcode' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Zipcode_frequencies.csv\n",
      "Unique values and frequencies for column 'Country' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Country_frequencies.csv\n",
      "Unique values and frequencies for column 'Timezone' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Timezone_frequencies.csv\n",
      "Unique values and frequencies for column 'Airport_Code' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Airport_Code_frequencies.csv\n",
      "Unique values and frequencies for column 'Weather_Timestamp' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Weather_Timestamp_frequencies.csv\n",
      "Unique values and frequencies for column 'Temperature(F)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Temperature(F)_frequencies.csv\n",
      "Unique values and frequencies for column 'Wind_Chill(F)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Wind_Chill(F)_frequencies.csv\n",
      "Unique values and frequencies for column 'Humidity(%)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Humidity(%)_frequencies.csv\n",
      "Unique values and frequencies for column 'Pressure(in)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Pressure(in)_frequencies.csv\n",
      "Unique values and frequencies for column 'Visibility(mi)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Visibility(mi)_frequencies.csv\n",
      "Unique values and frequencies for column 'Wind_Direction' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Wind_Direction_frequencies.csv\n",
      "Unique values and frequencies for column 'Wind_Speed(mph)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Wind_Speed(mph)_frequencies.csv\n",
      "Unique values and frequencies for column 'Precipitation(in)' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Precipitation(in)_frequencies.csv\n",
      "Unique values and frequencies for column 'Weather_Condition' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Weather_Condition_frequencies.csv\n",
      "Unique values and frequencies for column 'Amenity' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Amenity_frequencies.csv\n",
      "Unique values and frequencies for column 'Bump' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Bump_frequencies.csv\n",
      "Unique values and frequencies for column 'Crossing' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Crossing_frequencies.csv\n",
      "Unique values and frequencies for column 'Give_Way' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Give_Way_frequencies.csv\n",
      "Unique values and frequencies for column 'Junction' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Junction_frequencies.csv\n",
      "Unique values and frequencies for column 'No_Exit' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/No_Exit_frequencies.csv\n",
      "Unique values and frequencies for column 'Railway' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Railway_frequencies.csv\n",
      "Unique values and frequencies for column 'Roundabout' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Roundabout_frequencies.csv\n",
      "Unique values and frequencies for column 'Station' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Station_frequencies.csv\n",
      "Unique values and frequencies for column 'Stop' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Stop_frequencies.csv\n",
      "Unique values and frequencies for column 'Traffic_Calming' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Traffic_Calming_frequencies.csv\n",
      "Unique values and frequencies for column 'Traffic_Signal' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Traffic_Signal_frequencies.csv\n",
      "Unique values and frequencies for column 'Turning_Loop' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Turning_Loop_frequencies.csv\n",
      "Unique values and frequencies for column 'Sunrise_Sunset' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Sunrise_Sunset_frequencies.csv\n",
      "Unique values and frequencies for column 'Civil_Twilight' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Civil_Twilight_frequencies.csv\n",
      "Unique values and frequencies for column 'Nautical_Twilight' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Nautical_Twilight_frequencies.csv\n",
      "Unique values and frequencies for column 'Astronomical_Twilight' saved to /teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/Astronomical_Twilight_frequencies.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = '/teamspace/studios/this_studio/Assignment-TechstaX/data/unique_value_frequencies/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through each column and calculate unique values and their frequencies\n",
    "for column in data.columns:\n",
    "    unique_counts = data[column].value_counts(dropna=False)  # Include NaN values\n",
    "    output_df = unique_counts.reset_index()  # Convert to DataFrame\n",
    "    output_df.columns = ['Unique_Value', 'Frequency']  # Rename columns\n",
    "    \n",
    "    # Save the unique value frequencies to a CSV file\n",
    "    output_file = os.path.join(output_dir, f\"{column}_frequencies.csv\")\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(f\"Unique values and frequencies for column '{column}' saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:The following columns were not found in the dataset: {'Side', 'Number'}\n",
      "INFO:__main__:Successfully dropped 14 columns\n",
      "INFO:__main__:DataFrame shape changed from (7728394, 46) to (7728394, 32)\n",
      "INFO:fireducks.fallback:fallback_attr: name=Index.tolist reason=Index.__getattr__ for tolist is called \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Severity', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng', 'Distance(mi)', 'Description', 'City', 'County', 'State', 'Timezone', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Sunrise_Sunset']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "def drop_redundant_columns(df):\n",
    "    \"\"\"\n",
    "    Drops redundant columns from the accidents dataset.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame with accident data\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with redundant columns removed\n",
    "    \"\"\"\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # List of columns to drop\n",
    "    redundant_columns = [\n",
    "        'Source',\n",
    "        'End_Lat',\n",
    "        'End_Lng',\n",
    "        'Number',\n",
    "        'Street',\n",
    "        'Country',\n",
    "        'Airport_Code',\n",
    "        'Civil_Twilight',\n",
    "        'Nautical_Twilight',\n",
    "        'Astronomical_Twilight',\n",
    "        'Weather_Timestamp',\n",
    "        'ID',\n",
    "        'Turning_Loop',\n",
    "        'Wind_Chill(F)',\n",
    "        'Side',\n",
    "        'Zipcode'\n",
    "    ]\n",
    "    \n",
    "    # Store original shape\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    try:\n",
    "        # Check which columns actually exist in the dataframe\n",
    "        columns_to_drop = [col for col in redundant_columns if col in df.columns]\n",
    "        \n",
    "        # Log any columns that were in our list but not in the dataframe\n",
    "        missing_columns = set(redundant_columns) - set(df.columns)\n",
    "        if missing_columns:\n",
    "            logger.warning(f\"The following columns were not found in the dataset: {missing_columns}\")\n",
    "        \n",
    "        # Drop the columns\n",
    "        df_cleaned = df.drop(columns=columns_to_drop)\n",
    "        \n",
    "        # Log the results\n",
    "        columns_dropped = len(columns_to_drop)\n",
    "        logger.info(f\"Successfully dropped {columns_dropped} columns\")\n",
    "        logger.info(f\"DataFrame shape changed from {original_shape} to {df_cleaned.shape}\")\n",
    "        \n",
    "        return df_cleaned\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while dropping columns: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "# Example usage:\n",
    "data = drop_redundant_columns(data)\n",
    "\n",
    "# To verify the remaining columns:\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.map reason=input 'arg' is neither a dict nor a type to be casted \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 11 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather_Group\n",
      "Clear                  3405216\n",
      "Cloudy                 3163728\n",
      "Rain                    510564\n",
      "Poor Visibility         201398\n",
      "Unknown                 178798\n",
      "Snow                    160008\n",
      "Thunderstorm             88452\n",
      "Mixed Precipitation      13247\n",
      "Freezing Conditions       6049\n",
      "Dust/Sand                  747\n",
      "Severe Conditions          187\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_weather_conditions(weather_series):\n",
    "    \"\"\"\n",
    "    Groups weather conditions into broader categories.\n",
    "    \n",
    "    Args:\n",
    "        weather_series: pandas Series containing weather conditions\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with grouped weather conditions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create mapping dictionary for weather conditions\n",
    "    weather_mapping = {\n",
    "        # Clear conditions\n",
    "        'Fair': 'Clear',\n",
    "        'Clear': 'Clear',\n",
    "        'Fair / Windy': 'Clear',\n",
    "        \n",
    "        # Cloudy conditions\n",
    "        'Mostly Cloudy': 'Cloudy',\n",
    "        'Cloudy': 'Cloudy',\n",
    "        'Partly Cloudy': 'Cloudy',\n",
    "        'Overcast': 'Cloudy',\n",
    "        'Scattered Clouds': 'Cloudy',\n",
    "        'Cloudy / Windy': 'Cloudy',\n",
    "        'Mostly Cloudy / Windy': 'Cloudy',\n",
    "        'Partly Cloudy / Windy': 'Cloudy',\n",
    "        \n",
    "        # Rain conditions\n",
    "        'Light Rain': 'Rain',\n",
    "        'Rain': 'Rain',\n",
    "        'Heavy Rain': 'Rain',\n",
    "        'Light Drizzle': 'Rain',\n",
    "        'Light Rain / Windy': 'Rain',\n",
    "        'Rain / Windy': 'Rain',\n",
    "        'Heavy Rain / Windy': 'Rain',\n",
    "        'Drizzle': 'Rain',\n",
    "        'Light Rain Shower': 'Rain',\n",
    "        'Rain Shower': 'Rain',\n",
    "        'Rain Showers': 'Rain',\n",
    "        'Heavy Drizzle': 'Rain',\n",
    "        'Light Rain Showers': 'Rain',\n",
    "        'Heavy Rain Showers': 'Rain',\n",
    "        'Light Drizzle / Windy': 'Rain',\n",
    "        'Drizzle / Windy': 'Rain',\n",
    "        'Rain Shower / Windy': 'Rain',\n",
    "        'Heavy Rain Shower / Windy': 'Rain',\n",
    "        'Drizzle and Fog': 'Rain',\n",
    "        \n",
    "        # Snow conditions\n",
    "        'Light Snow': 'Snow',\n",
    "        'Snow': 'Snow',\n",
    "        'Heavy Snow': 'Snow',\n",
    "        'Light Snow / Windy': 'Snow',\n",
    "        'Snow / Windy': 'Snow',\n",
    "        'Heavy Snow / Windy': 'Snow',\n",
    "        'Blowing Snow': 'Snow',\n",
    "        'Blowing Snow / Windy': 'Snow',\n",
    "        'Light Snow Shower': 'Snow',\n",
    "        'Snow Showers': 'Snow',\n",
    "        'Light Snow Showers': 'Snow',\n",
    "        'Light Snow Shower / Windy': 'Snow',\n",
    "        'Snow Grains': 'Snow',\n",
    "        'Light Snow Grains': 'Snow',\n",
    "        'Drifting Snow': 'Snow',\n",
    "        'Drifting Snow / Windy': 'Snow',\n",
    "        'Low Drifting Snow': 'Snow',\n",
    "        'Heavy Blowing Snow': 'Snow',\n",
    "        'Light Blowing Snow': 'Snow',\n",
    "        'Blowing Snow Nearby': 'Snow',\n",
    "        \n",
    "        # Thunderstorm conditions\n",
    "        'Thunder': 'Thunderstorm',\n",
    "        'T-Storm': 'Thunderstorm',\n",
    "        'Heavy T-Storm': 'Thunderstorm',\n",
    "        'Thunder in the Vicinity': 'Thunderstorm',\n",
    "        'Light Rain with Thunder': 'Thunderstorm',\n",
    "        'Light Thunderstorms and Rain': 'Thunderstorm',\n",
    "        'Thunderstorm': 'Thunderstorm',\n",
    "        'Heavy Thunderstorms and Rain': 'Thunderstorm',\n",
    "        'Thunderstorms and Rain': 'Thunderstorm',\n",
    "        'Heavy T-Storm / Windy': 'Thunderstorm',\n",
    "        'T-Storm / Windy': 'Thunderstorm',\n",
    "        'Thunder / Windy': 'Thunderstorm',\n",
    "        'Thunder and Hail': 'Thunderstorm',\n",
    "        'Thunder and Hail / Windy': 'Thunderstorm',\n",
    "        'Light Thunderstorm': 'Thunderstorm',\n",
    "        \n",
    "        # Freezing conditions\n",
    "        'Light Freezing Rain': 'Freezing Conditions',\n",
    "        'Light Freezing Drizzle': 'Freezing Conditions',\n",
    "        'Freezing Rain': 'Freezing Conditions',\n",
    "        'Freezing Drizzle': 'Freezing Conditions',\n",
    "        'Heavy Freezing Rain': 'Freezing Conditions',\n",
    "        'Light Freezing Rain / Windy': 'Freezing Conditions',\n",
    "        'Freezing Rain / Windy': 'Freezing Conditions',\n",
    "        'Heavy Freezing Rain / Windy': 'Freezing Conditions',\n",
    "        'Heavy Freezing Drizzle': 'Freezing Conditions',\n",
    "        'Light Freezing Fog': 'Freezing Conditions',\n",
    "        \n",
    "        # Mixed precipitation\n",
    "        'Wintry Mix': 'Mixed Precipitation',\n",
    "        'Snow and Sleet': 'Mixed Precipitation',\n",
    "        'Light Snow and Sleet': 'Mixed Precipitation',\n",
    "        'Wintry Mix / Windy': 'Mixed Precipitation',\n",
    "        'Snow and Sleet / Windy': 'Mixed Precipitation',\n",
    "        'Light Snow and Sleet / Windy': 'Mixed Precipitation',\n",
    "        'Thunder / Wintry Mix': 'Mixed Precipitation',\n",
    "        'Thunder / Wintry Mix / Windy': 'Mixed Precipitation',\n",
    "        'Rain and Sleet': 'Mixed Precipitation',\n",
    "        'Sleet': 'Mixed Precipitation',\n",
    "        'Light Sleet': 'Mixed Precipitation',\n",
    "        'Heavy Sleet': 'Mixed Precipitation',\n",
    "        'Sleet / Windy': 'Mixed Precipitation',\n",
    "        'Light Sleet / Windy': 'Mixed Precipitation',\n",
    "        'Heavy Sleet / Windy': 'Mixed Precipitation',\n",
    "        \n",
    "        # Poor visibility conditions\n",
    "        'Fog': 'Poor Visibility',\n",
    "        'Haze': 'Poor Visibility',\n",
    "        'Smoke': 'Poor Visibility',\n",
    "        'Fog / Windy': 'Poor Visibility',\n",
    "        'Haze / Windy': 'Poor Visibility',\n",
    "        'Smoke / Windy': 'Poor Visibility',\n",
    "        'Patches of Fog': 'Poor Visibility',\n",
    "        'Mist': 'Poor Visibility',\n",
    "        'Shallow Fog': 'Poor Visibility',\n",
    "        'Patches of Fog / Windy': 'Poor Visibility',\n",
    "        'Mist / Windy': 'Poor Visibility',\n",
    "        'Shallow Fog / Windy': 'Poor Visibility',\n",
    "        'Light Haze': 'Poor Visibility',\n",
    "        'Light Fog': 'Poor Visibility',\n",
    "        'Partial Fog': 'Poor Visibility',\n",
    "        'Partial Fog / Windy': 'Poor Visibility',\n",
    "        'Heavy Smoke': 'Poor Visibility',\n",
    "        \n",
    "        # Severe conditions\n",
    "        'Tornado': 'Severe Conditions',\n",
    "        'Funnel Cloud': 'Severe Conditions',\n",
    "        'Small Hail': 'Severe Conditions',\n",
    "        'Hail': 'Severe Conditions',\n",
    "        'Light Hail': 'Severe Conditions',\n",
    "        'Volcanic Ash': 'Severe Conditions',\n",
    "        'Heavy Thunderstorms with Small Hail': 'Severe Conditions',\n",
    "        \n",
    "        # Dust/Sand conditions\n",
    "        'Blowing Dust': 'Dust/Sand',\n",
    "        'Widespread Dust': 'Dust/Sand',\n",
    "        'Sand / Dust Whirlwinds': 'Dust/Sand',\n",
    "        'Blowing Dust / Windy': 'Dust/Sand',\n",
    "        'Widespread Dust / Windy': 'Dust/Sand',\n",
    "        'Sand': 'Dust/Sand',\n",
    "        'Sand / Dust Whirls Nearby': 'Dust/Sand',\n",
    "        'Sand / Dust Whirlwinds / Windy': 'Dust/Sand',\n",
    "        'Duststorm': 'Dust/Sand',\n",
    "        'Blowing Sand': 'Dust/Sand',\n",
    "        'Dust Whirls': 'Dust/Sand',\n",
    "        'Sand / Windy': 'Dust/Sand'\n",
    "    }\n",
    "    \n",
    "    # Replace empty strings and N/A with 'Unknown'\n",
    "    weather_series = weather_series.fillna('Unknown')\n",
    "    weather_series = weather_series.replace('', 'Unknown')\n",
    "    weather_series = weather_series.replace('N/A Precipitation', 'Unknown')\n",
    "    \n",
    "    # Map the weather conditions to their groups\n",
    "    return weather_series.map(lambda x: weather_mapping.get(x, 'Unknown'))\n",
    "\n",
    "data['Weather_Group'] = group_weather_conditions(data['Weather_Condition'])\n",
    "data = data.drop(columns=['Weather_Condition'])\n",
    "# To see the distribution of the new groups\n",
    "print(data['Weather_Group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=Series.map reason=input 'arg' is neither a dict nor a type to be casted \n",
      "INFO:fireducks.fallback:fallback_attr: name=Series.__repr__ reason=with full data of size: 11 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind_Direction_Group\n",
      "South        1331314\n",
      "Calm         1330181\n",
      "West         1281251\n",
      "North        1049274\n",
      "East          909244\n",
      "Northwest     369352\n",
      "Variable      364562\n",
      "Southwest     364470\n",
      "Southeast     294901\n",
      "Northeast     258639\n",
      "Unknown       175206\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_wind_directions(wind_series):\n",
    "    \"\"\"\n",
    "    Groups wind directions into 8 main cardinal directions.\n",
    "    \n",
    "    Args:\n",
    "        wind_series: pandas Series containing wind directions\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with grouped wind directions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create mapping dictionary for wind directions\n",
    "    wind_mapping = {\n",
    "        # North (337.5° - 22.5°)\n",
    "        'N': 'North',\n",
    "        'North': 'North',\n",
    "        'NNE': 'North',\n",
    "        'NNW': 'North',\n",
    "        \n",
    "        # East (67.5° - 112.5°)\n",
    "        'E': 'East',\n",
    "        'East': 'East',\n",
    "        'ENE': 'East',\n",
    "        'ESE': 'East',\n",
    "        \n",
    "        # South (157.5° - 202.5°)\n",
    "        'S': 'South',\n",
    "        'South': 'South',\n",
    "        'SSE': 'South',\n",
    "        'SSW': 'South',\n",
    "        \n",
    "        # West (247.5° - 292.5°)\n",
    "        'W': 'West',\n",
    "        'West': 'West',\n",
    "        'WNW': 'West',\n",
    "        'WSW': 'West',\n",
    "        \n",
    "        # Northeast (22.5° - 67.5°)\n",
    "        'NE': 'Northeast',\n",
    "        \n",
    "        # Southeast (112.5° - 157.5°)\n",
    "        'SE': 'Southeast',\n",
    "        \n",
    "        # Southwest (202.5° - 247.5°)\n",
    "        'SW': 'Southwest',\n",
    "        \n",
    "        # Northwest (292.5° - 337.5°)\n",
    "        'NW': 'Northwest',\n",
    "        \n",
    "        # Calm/Variable conditions\n",
    "        'CALM': 'Calm',\n",
    "        'Calm': 'Calm',\n",
    "        'VAR': 'Variable',\n",
    "        'Variable': 'Variable'\n",
    "    }\n",
    "    \n",
    "    # Replace empty strings and missing values with 'Unknown'\n",
    "    wind_series = wind_series.fillna('Unknown')\n",
    "    wind_series = wind_series.replace('', 'Unknown')\n",
    "    \n",
    "    # Map the wind directions to their groups\n",
    "    return wind_series.map(lambda x: wind_mapping.get(x, 'Unknown'))\n",
    "\n",
    "\n",
    "data['Wind_Direction_Group'] = group_wind_directions(data['Wind_Direction'])\n",
    "data.drop(columns=['Wind_Direction'], inplace=True)\n",
    "# To see the distribution of the new groups\n",
    "print(data['Wind_Direction_Group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def categorize_time_of_day(hour):\n",
    "    \"\"\"\n",
    "    Categorizes the hour into time of day\n",
    "    \n",
    "    Args:\n",
    "        hour: int (0-23)\n",
    "    Returns:\n",
    "        str: time of day category\n",
    "    \"\"\"\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 15:\n",
    "        return 'Noon'\n",
    "    elif 15 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "def process_time_features(df):\n",
    "    \"\"\"\n",
    "    Process time-related features:\n",
    "    1. Extract time of day from Start_Time\n",
    "    2. Calculate accident duration in minutes\n",
    "    3. Drop Sunrise_Sunset column\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with Start_Time and End_Time columns\n",
    "    Returns:\n",
    "        pandas DataFrame with new time features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert Start_Time and End_Time to datetime if they're not already\n",
    "        df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "        df['End_Time'] = pd.to_datetime(df['End_Time'])\n",
    "        \n",
    "        # Extract hour from Start_Time\n",
    "        df['Hour'] = df['Start_Time'].dt.hour\n",
    "        \n",
    "        # Add Time_Of_Day column\n",
    "        df['Time_Of_Day'] = df['Hour'].apply(categorize_time_of_day)\n",
    "        \n",
    "        # Calculate duration in minutes\n",
    "        df['Duration_Minutes'] = ((df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60).round(2)\n",
    "        \n",
    "        # Drop intermediate and redundant columns\n",
    "        columns_to_drop = ['Hour', 'Sunrise_Sunset', 'Start_Time', 'End_Time']\n",
    "        existing_columns = [col for col in columns_to_drop if col in df.columns]\n",
    "        df = df.drop(columns=existing_columns)\n",
    "        \n",
    "        print(f\"Time of day distribution:\\n{df['Time_Of_Day'].value_counts()}\\n\")\n",
    "        print(f\"Duration statistics (in minutes):\\n{df['Duration_Minutes'].describe()}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing time features: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "data = process_time_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fireducks.fallback:fallback_attr: name=DataFrame.select_dtypes reason=DataFrame.__getattr__ for select_dtypes is called \n"
     ]
    }
   ],
   "source": [
    "def count_unique_values(df):\n",
    "    \"\"\"\n",
    "    This function returns a dictionary where the keys are column names,\n",
    "    and the values are the count of unique values in each column.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with column names as keys and unique value counts as values.\n",
    "    \"\"\"\n",
    "    unique_values = {}\n",
    "    for col in df.select_dtypes(exclude=['number']).columns:\n",
    "        unique_values[col] = df[col].dropna().unique().tolist()\n",
    "    return unique_values\n",
    "\n",
    "\n",
    "unique_value_counts = count_unique_values(data)\n",
    "\n",
    "# Print the counts for each column\n",
    "for column, count in unique_value_counts.items():\n",
    "    print(f\"Column: {column}, Unique Values: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
